---
title: "citationchaser"
author: "Neal R Haddaway"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{citationchaser}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## About 'citation chasing'

'Citation chasing' is the name given to the process of tracking down records of which academic publications are connected to one or more starting articles, based on which articles are included in the given article reference list(s) ('backward citation chasing') and which articles themselves cite the starting article(s) ('forward citation chasing'). The process is somteims referred to as 'pearl growing' or (in the case of backward citation chasing) bibliographic checking. Citation chasing is an integral part of most systematic review methods, and is a supplementary means of finding additional relevant articles for a review, used alongside bibliographic database searches and other methods, like grey literature searching.

Traditionally, the process of citation chasing in systematic searching would be done manually, checking each citing or cited record one-by-one either against the original inclusion/eligibility criteria, or first against the search results (to remove records already screened for relevance in earlier steps of the review) and then against the inclusion criteria. Needless to say, this process can take a LOT of time. More than that, there is often a lot of overlap between records found through citation chasing and records already brought back in searches, and also overlap amongst the records found through citation chasing. it's also a messy and challenging process to document and keep track of.


## About citationchaser

citationchaser  makes use of the free-to-use bibliographic database The Lens.org, and its free (with some limitations) API (Application Programming Interface). The API allows us to send requests to the lens.org server, which then returns results from the Lens.org database. Lens.org includes >225 million bibliographic records, and encompasses all of Microsoft Academic Graph, CrossRef, PubMed and PubMed Central, and Core (for more details <a href="https://about.lens.org/" target="_blank">click here</a>).

citationchaser takes as its input key identification information for one or more starting articles and tracks them down in the Lens.org database. It then identifies and returns a listn of all articles referenced in these starting articles (backward citation chasing) and/or all articles citing the starting articles (forward citation chasing). The output is an interoperable RIS file formatted for use in reference and review management software.


## Using citationchaser
Let's say we have four articles and we want to know who they cited. In this case we will begin with a list of DOIs (digital object identifiers), but you could also use PubMed IDs (or PubMed Central IDs), Core IDs, or Microsoft Academic IDs. The function will work with article titles, but the sensitivity is likely to be low, since many articles have very similar titles, and minor punctuation differences in how records are indexed in databases may make it impossible to find them. DOIs are widely used and highly specific, so that's a good place to start:

```{r, eval=FALSE}
devtools::install_github("nealhaddaway/citationchaser")
library(citationchaser)
article_list <- c("10.1007/978-3-642-37048-9_13", "10.1111/sum.12030", "10.5194/bg-13-3619-2016", "10.1016/j.agee.2012.09.006")
```

The DOIs need to be provided in short form - please remove the 'https://doi.org/' stem.

All we need to do now is specify some settings and bring back the reference lists of all four articles. 'get_records' tells the function which direction to search for citations: in this case references in the starting articles. The 'token' is provided by Lens.org after applying ot use the service. It is a unique code that allows us to send queries to the server. We are limmited by the API infrastructure to 10 requests per minute, so the function will take a short amount of time to run.

```{r, echo=TRUE}
get_refs(article_list, 
         get_records = 'references', 
         token = 'K4FaRccEYJJgd0MaSUVy1MXNcgzvB1Y25PWfyEeNicqxmndHKk0v')
```

The report printed to the console describes what was found on lens.org, and the RIS file containing our results is saved to our working directory. In you choose to search for citations and references (get_records = 'both') then you will have two reports and two RIS files. 

Another current limitation of the package as it stands is that each query is limited to 1,000 records (anything beyond this isn't returned). If your download contains 1,000 records or more, for now it's best to split the input article list up to avoid losing information. The next version of the package will allow multiple requests in batches of <1,000 to circumvent this limitation. Thanks for bearing with me!
